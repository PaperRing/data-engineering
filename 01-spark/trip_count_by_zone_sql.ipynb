{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2515db02",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa7e7dea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/01/06 18:50:46 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "22/01/06 18:50:46 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "22/01/06 18:50:46 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName(\"trip_count_by_zone_sql\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c113f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"/Users/junghee/data-engineering/01-spark/data\"\n",
    "trip_file = \"/fhvhv_tripdata_2020-03.csv\"\n",
    "zone_file = \"taxi+_zone_lookup.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6a446cba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "trip_data = spark.read.csv(f\"file:///{directory}/{trip_file}\", inferSchema = True, header = True)\n",
    "zone_data = spark.read.csv(f\"file:///{directory}/{zone_file}\", inferSchema = True, header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "44752182",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+--------------------+------------+\n",
      "|LocationID|      Borough|                Zone|service_zone|\n",
      "+----------+-------------+--------------------+------------+\n",
      "|         1|          EWR|      Newark Airport|         EWR|\n",
      "|         2|       Queens|         Jamaica Bay|   Boro Zone|\n",
      "|         3|        Bronx|Allerton/Pelham G...|   Boro Zone|\n",
      "|         4|    Manhattan|       Alphabet City| Yellow Zone|\n",
      "|         5|Staten Island|       Arden Heights|   Boro Zone|\n",
      "+----------+-------------+--------------------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "zone_data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bead65ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "trip_data.createOrReplaceTempView(\"trip\")\n",
    "zone_data.createOrReplaceTempView(\"zone\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "94a8597a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+--------------------+------------+\n",
      "|LocationID|      Borough|                Zone|service_zone|\n",
      "+----------+-------------+--------------------+------------+\n",
      "|         1|          EWR|      Newark Airport|         EWR|\n",
      "|         2|       Queens|         Jamaica Bay|   Boro Zone|\n",
      "|         3|        Bronx|Allerton/Pelham G...|   Boro Zone|\n",
      "|         4|    Manhattan|       Alphabet City| Yellow Zone|\n",
      "|         5|Staten Island|       Arden Heights|   Boro Zone|\n",
      "+----------+-------------+--------------------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select * from zone\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9391998b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+--------------------+-------------------+-------------------+------------+------------+-------+\n",
      "|hvfhs_license_num|dispatching_base_num|    pickup_datetime|   dropoff_datetime|PULocationID|DOLocationID|SR_Flag|\n",
      "+-----------------+--------------------+-------------------+-------------------+------------+------------+-------+\n",
      "|           HV0005|              B02510|2020-03-01 00:03:40|2020-03-01 00:23:39|          81|         159|   null|\n",
      "|           HV0005|              B02510|2020-03-01 00:28:05|2020-03-01 00:38:57|         168|         119|   null|\n",
      "|           HV0003|              B02764|2020-03-01 00:03:07|2020-03-01 00:15:04|         137|         209|      1|\n",
      "|           HV0003|              B02764|2020-03-01 00:18:42|2020-03-01 00:38:42|         209|          80|   null|\n",
      "|           HV0003|              B02764|2020-03-01 00:44:24|2020-03-01 00:58:44|         256|         226|   null|\n",
      "+-----------------+--------------------+-------------------+-------------------+------------+------------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select * from trip\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1face166",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 37:>                                                       (0 + 12) / 12]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-------+\n",
      "|      Borough|   trip|\n",
      "+-------------+-------+\n",
      "|    Manhattan|4953140|\n",
      "|     Brooklyn|3735764|\n",
      "|       Queens|2437383|\n",
      "|        Bronx|2086592|\n",
      "|Staten Island| 178818|\n",
      "|      Unknown|    845|\n",
      "|          EWR|    362|\n",
      "+-------------+-------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 37:====>                                                   (1 + 11) / 12]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select Borough, count(*) as trip \\\n",
    "            from (select Borough \\\n",
    "                        from trip join zone \\\n",
    "                        on trip.PULocationID = zone.LocationID)\\\n",
    "            group by Borough\\\n",
    "            order by trip desc\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0795f2ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Parsed Logical Plan ==\n",
      "'Sort ['trip DESC NULLS LAST], true\n",
      "+- 'Aggregate ['Borough], ['Borough, 'count(1) AS trip#480]\n",
      "   +- 'SubqueryAlias __auto_generated_subquery_name\n",
      "      +- 'Project ['Borough]\n",
      "         +- 'Join Inner, ('trip.DOLocationID = 'zone.LocationID)\n",
      "            :- 'UnresolvedRelation [trip], [], false\n",
      "            +- 'UnresolvedRelation [zone], [], false\n",
      "\n",
      "== Analyzed Logical Plan ==\n",
      "Borough: string, trip: bigint\n",
      "Sort [trip#480L DESC NULLS LAST], true\n",
      "+- Aggregate [Borough#176], [Borough#176, count(1) AS trip#480L]\n",
      "   +- SubqueryAlias __auto_generated_subquery_name\n",
      "      +- Project [Borough#176]\n",
      "         +- Join Inner, (DOLocationID#150 = LocationID#175)\n",
      "            :- SubqueryAlias trip\n",
      "            :  +- View (`trip`, [hvfhs_license_num#145,dispatching_base_num#146,pickup_datetime#147,dropoff_datetime#148,PULocationID#149,DOLocationID#150,SR_Flag#151])\n",
      "            :     +- Relation [hvfhs_license_num#145,dispatching_base_num#146,pickup_datetime#147,dropoff_datetime#148,PULocationID#149,DOLocationID#150,SR_Flag#151] csv\n",
      "            +- SubqueryAlias zone\n",
      "               +- View (`zone`, [LocationID#175,Borough#176,Zone#177,service_zone#178])\n",
      "                  +- Relation [LocationID#175,Borough#176,Zone#177,service_zone#178] csv\n",
      "\n",
      "== Optimized Logical Plan ==\n",
      "Sort [trip#480L DESC NULLS LAST], true\n",
      "+- Aggregate [Borough#176], [Borough#176, count(1) AS trip#480L]\n",
      "   +- Project [Borough#176]\n",
      "      +- Join Inner, (DOLocationID#150 = LocationID#175)\n",
      "         :- Project [DOLocationID#150]\n",
      "         :  +- Filter isnotnull(DOLocationID#150)\n",
      "         :     +- Relation [hvfhs_license_num#145,dispatching_base_num#146,pickup_datetime#147,dropoff_datetime#148,PULocationID#149,DOLocationID#150,SR_Flag#151] csv\n",
      "         +- Project [LocationID#175, Borough#176]\n",
      "            +- Filter isnotnull(LocationID#175)\n",
      "               +- Relation [LocationID#175,Borough#176,Zone#177,service_zone#178] csv\n",
      "\n",
      "== Physical Plan ==\n",
      "AdaptiveSparkPlan isFinalPlan=false\n",
      "+- Sort [trip#480L DESC NULLS LAST], true, 0\n",
      "   +- Exchange rangepartitioning(trip#480L DESC NULLS LAST, 200), ENSURE_REQUIREMENTS, [id=#1254]\n",
      "      +- HashAggregate(keys=[Borough#176], functions=[count(1)], output=[Borough#176, trip#480L])\n",
      "         +- Exchange hashpartitioning(Borough#176, 200), ENSURE_REQUIREMENTS, [id=#1251]\n",
      "            +- HashAggregate(keys=[Borough#176], functions=[partial_count(1)], output=[Borough#176, count#485L])\n",
      "               +- Project [Borough#176]\n",
      "                  +- BroadcastHashJoin [DOLocationID#150], [LocationID#175], Inner, BuildRight, false\n",
      "                     :- Filter isnotnull(DOLocationID#150)\n",
      "                     :  +- FileScan csv [DOLocationID#150] Batched: false, DataFilters: [isnotnull(DOLocationID#150)], Format: CSV, Location: InMemoryFileIndex(1 paths)[file:/Users/junghee/data-engineering/01-spark/data/fhvhv_tripdata_2020..., PartitionFilters: [], PushedFilters: [IsNotNull(DOLocationID)], ReadSchema: struct<DOLocationID:int>\n",
      "                     +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, false] as bigint)),false), [id=#1246]\n",
      "                        +- Filter isnotnull(LocationID#175)\n",
      "                           +- FileScan csv [LocationID#175,Borough#176] Batched: false, DataFilters: [isnotnull(LocationID#175)], Format: CSV, Location: InMemoryFileIndex(1 paths)[file:/Users/junghee/data-engineering/01-spark/data/taxi+_zone_lookup.csv], PartitionFilters: [], PushedFilters: [IsNotNull(LocationID)], ReadSchema: struct<LocationID:int,Borough:string>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select Borough, count(*) as trip \\\n",
    "            from (select Borough \\\n",
    "                        from trip join zone \\\n",
    "                        on trip.DOLocationID = zone.LocationID)\\\n",
    "            group by Borough\\\n",
    "            order by trip desc\").explain(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5a9d44",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
